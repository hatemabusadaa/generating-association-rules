{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Scoring-Dataset-5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Initial data exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A2. Calculate and analyze descriptive statistics for each attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Frequency of Values for Each Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    if column != \"User_ID\":\n",
    "        value_counts = data[column].value_counts()\n",
    "        value_counts.plot(kind='bar', color=\"#1f77b4\", edgecolor=\"black\")\n",
    "        plt.title(f'Frequency of Values for {column}')\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Distribution, Measures of Central Tendency & Measures of Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    if column != \"User_ID\":\n",
    "        mean_value = data[column].mean()\n",
    "        median_value = data[column].median()\n",
    "        variance_value = data[column].var()\n",
    "        percentiles_value = data[column].quantile([0.25, 0.5, 0.75])\n",
    "        data[column].plot(kind='hist', bins=50, color=\"#1f77b4\", edgecolor=\"black\")\n",
    "        plt.axvline(mean_value, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean_value:.2f}')\n",
    "        plt.title(f\"Distribution of {column} (Mean: {mean_value:.2f}) (Median: {median_value:.2f})\\n(Variance: {variance_value:.2f})\")\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print(percentiles_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    if column != \"User_ID\":\n",
    "        data[column].plot(kind=\"box\", sym=\"o\", patch_artist=True, \n",
    "                        boxprops={\"facecolor\": \"#1f77b4\", \"linewidth\": 0},\n",
    "                        medianprops={\"color\": \"white\", \"linewidth\": 2},\n",
    "                        whiskerprops={\"color\": \"#1f77b4\", \"linewidth\": 2},\n",
    "                        capprops={\"color\": \"#1f77b4\", \"linewidth\": 2})\n",
    "        plt.title(f'Boxplot for {column}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A3. Advanced exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data.copy()\n",
    "# Identify categorical columns\n",
    "categorical_columns = [col for col in data_copy.columns if data_copy[col].dtype == \"object\"]\n",
    "\n",
    "# Apply label encoding to categorical columns\n",
    "le = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    data_copy[col] = le.fit_transform(data_copy[col])\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "sns.pairplot(data_copy.drop(columns=[\"User_ID\",\"Browsed_Electronics_12Mo\",\"Bought_Electronics_12Mo\",\"Bought_Digital_Media_18Mo\",\"Bought_Digital_Books\"]), hue=\"Gender\", markers=[\"o\", \"s\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Data pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B1. Binning and Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data (replace with your actual data or file path)\n",
    "# Option 1: Provide data directly  # Replace with your age values\n",
    "\n",
    "# Option 2: Read from CSV file\n",
    "ages = data['Age']\n",
    "# Equi-width binning\n",
    "bins_equi_width = pd.cut(ages, bins=3, labels=['bin1','bin2','bin3'])  # Labels=False for bin indices\n",
    "\n",
    "# Equi-depth binning\n",
    "bins_equi_depth = pd.qcut(ages, q=3, labels=['bin1','bin2','bin3'])\n",
    "\n",
    "# Print the bin assignments for each technique\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Add new columns for bin assignments\n",
    "data[\"Equi-Width Bin\"] = bins_equi_width\n",
    "data[\"Equi-Depth Bin\"] = bins_equi_depth\n",
    "\n",
    "\n",
    "\n",
    "# Select only the desired columns\n",
    "\n",
    "smothed_width_data_bin1 = int(data[data[\"Equi-Width Bin\"]=='bin1']['Age'].mean())\n",
    "smothed_width_data_bin2 = int(data[data[\"Equi-Width Bin\"]=='bin2']['Age'].mean())\n",
    "smothed_width_data_bin3 = int(data[data[\"Equi-Width Bin\"]=='bin3']['Age'].mean())\n",
    "smothed_dipth_data_bin1 = int(data[data[\"Equi-Depth Bin\"]=='bin1']['Age'].mean())\n",
    "smothed_dipth_data_bin2 = int(data[data[\"Equi-Depth Bin\"]=='bin2']['Age'].mean())\n",
    "smothed_dipth_data_bin3 = int(data[data[\"Equi-Depth Bin\"]=='bin3']['Age'].mean())\n",
    "data['smothed_width_data'] = 4\n",
    "data['smothed_depth_data'] = 4\n",
    "for index,row in data.iterrows():\n",
    "        #smothing in width\n",
    "        if row['Equi-Width Bin']=='bin1':\n",
    "            data.at[index,'smothed_width_data'] = smothed_width_data_bin1\n",
    "        elif row['Equi-Width Bin']=='bin2':\n",
    "            data.at[index,'smothed_width_data'] = smothed_width_data_bin2\n",
    "        else:\n",
    "            data.at[index,'smothed_width_data'] = smothed_width_data_bin3\n",
    "        #smothing in depth    \n",
    "        if row['Equi-Depth Bin']=='bin1':\n",
    "            data.at[index,'smothed_depth_data'] = smothed_dipth_data_bin1  \n",
    "        elif row['Equi-Depth Bin']=='bin2':\n",
    "             data.at[index,'smothed_depth_data'] = smothed_dipth_data_bin2\n",
    "        else:\n",
    "             data.at[index,'smothed_depth_data'] = smothed_dipth_data_bin3     \n",
    "                 \n",
    "\n",
    "    \n",
    "binned_data = data[[\"Equi-Width Bin\", \"Equi-Depth Bin\",\"smothed_width_data\",\"smothed_depth_data\"]]   \n",
    "\n",
    "print(binned_data.head(10))\n",
    "# Export the selected columns to a new CSV file\n",
    "binned_data.to_csv('bins_only.csv', index=False)  # Adjust filename as needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B2. Normalize \"Age\" attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Min-max normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the minimum and maximum values of the \"ages\" column\n",
    "min_age = data[\"Age\"].min()\n",
    "max_age = data[\"Age\"].max()\n",
    "\n",
    "# Scale the \"ages\" column using min-max scaling\n",
    "data[\"Ages_scaled\"] = (data[\"Age\"] - min_age) / (max_age - min_age)\n",
    "\n",
    "# Save the scaled data to a new CSV file (optional)\n",
    "data.to_csv(\"scaled_data.csv\", index=False)\n",
    "print(data[\"Ages_scaled\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Z-score normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Z-score normalization for 'Age'\n",
    "mean_age = data['Age'].mean()\n",
    "std_age = data['Age'].std()\n",
    "\n",
    "data['Age_ZScore'] = (data['Age'] - mean_age) / std_age\n",
    "\n",
    "data.to_csv(\"scaled_data.csv\", index=False)\n",
    "print(data['Age_ZScore'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B3. Discretize \"Age\" attribute:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Divides the continuous \"Age\" into five categories: Teenager, Young, Mid-Age, Mature, and Old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define age categories\n",
    "bins = [1, 16, 35, 55, 70, 150]\n",
    "labels = ['Teenager', 'Young', 'Mid_Age', 'Mature', 'Old']\n",
    "\n",
    "# Create a new column for age categories\n",
    "data['Age_Category'] = pd.cut(data['Age'], bins=bins, labels=labels)\n",
    "\n",
    "# Display the DataFrame with the new 'Age_Category' column\n",
    "data.to_csv(\"scaled_data.csv\", index=False)\n",
    "\n",
    "# Display the frequency of each category\n",
    "category_counts = data['Age_Category'].value_counts()\n",
    "print(f\"\\nFrequency of each category:\\n{category_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B4. Binarize \"Gender\" attribute:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Converts the categorical \"Gender\" variable into two binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'Gender' to binary values\n",
    "gender_mapping = {'M': 1, 'F': 0}\n",
    "data['Gender_Binary'] = data['Gender'].map(gender_mapping)\n",
    "\n",
    "data.to_csv(\"scaled_data.csv\", index=False)\n",
    "\n",
    "print(data[['Gender','Gender_Binary']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Association Rules Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Load the dataset (assuming headers are present)\n",
    "data2 = pd.read_csv(\"Community-participation-Dataset(5).csv\")\n",
    "\n",
    "# Preprocess the data2\n",
    "data2 = data2[['Family', 'Hobbies', 'Social_Club', 'Political', 'Professional', 'Religious', 'Support_Group','Gender']]\n",
    "data2 = data2.fillna(False)\n",
    "data2 = data2.replace({\"Yes\": True, \"No\": False,\"M\":True ,\"F\":False })\n",
    "\n",
    "\n",
    "# Apply Apriori algorithm (directly using the DataFrame)\n",
    "frequent_itemsets = apriori(data2, min_support=0.1, use_colnames=True)\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "# Display rules with additional metrics\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence']])\n",
    "dataf = rules[['antecedents', 'consequents', 'support', 'confidence']]\n",
    "dataf.to_csv(\"Apriori.csv\",index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
